{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "save_and_restore_models.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dfsj66011/learning_note/blob/master/tensorflow_tutorial/save_and_restore_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g_nWetWWd_ns"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "2pHVBk_seED1",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "N_fMsQ-N8I7j",
        "colab": {}
      },
      "source": [
        "#@title MIT License\n",
        "#\n",
        "# Copyright (c) 2017 François Chollet\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a\n",
        "# copy of this software and associated documentation files (the \"Software\"),\n",
        "# to deal in the Software without restriction, including without limitation\n",
        "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
        "# and/or sell copies of the Software, and to permit persons to whom the\n",
        "# Software is furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
        "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
        "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
        "# DEALINGS IN THE SOFTWARE."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pZJ3uY9O17VN"
      },
      "source": [
        "# 保存和恢复模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M4Ata7_wMul1"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/keras/save_and_restore_models\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_restore_models.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_restore_models.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mBdde4YJeJKF"
      },
      "source": [
        "模型进度可在训练期间和之后保存。这意味着，您可以从上次暂停的地方继续训练模型，避免训练时间过长。此外，可以保存意味着您可以分享模型，而他人可以对您的工作成果进行再创作。发布研究模型和相关技术时，大部分机器学习从业者会分享以下内容：\n",
        "\n",
        "* 用于创建模型的代码，以及\n",
        "* 模型的训练权重或参数\n",
        "\n",
        "分享此类数据有助于他人了解模型的工作原理并尝试使用新数据自行尝试模型。\n",
        "\n",
        "注意：请谨慎使用不可信的代码 - TensorFlow 模型就是代码。有关详情，请参阅 [安全地使用 TensorFlow](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\n",
        "\n",
        "### 选项\n",
        "\n",
        "您可以通过多种不同的方法保存 TensorFlow 模型，具体取决于您使用的 API。本指南使用的是 [tf.keras](https://www.tensorflow.org/guide/keras)，它是一种用于在 TensorFlow 中构建和训练模型的高阶 API。要了解其他方法，请参阅 TensorFlow [保存和恢复指南](https://www.tensorflow.org/guide/saved_model)或在 [Eager 中保存](https://www.tensorflow.org/guide/eager#object-based_saving)。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xCUREq7WXgvg"
      },
      "source": [
        "## 设置\n",
        "\n",
        "\n",
        "### 安装和导入"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7l0MiTOrXtNv"
      },
      "source": [
        "安装并导入 TensorFlow 和依赖项："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RzIOVSdnMYyO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "c7dcdc99-1174-4fde-c1ff-afc309d97a23"
      },
      "source": [
        "!pip install h5py pyyaml\n",
        "!pip install tf_nightly"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.16.4)\n",
            "Requirement already satisfied: tf_nightly in /usr/local/lib/python3.6/dist-packages (1.15.0.dev20190724)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (0.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (2.3.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (3.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.0.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.16.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.11.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (0.2.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.12.0)\n",
            "Requirement already satisfied: tb-nightly<1.16.0a0,>=1.15.0a0 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.15.0a20190724)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (0.33.4)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (0.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.1.0)\n",
            "Requirement already satisfied: tf-estimator-nightly in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (1.14.0.dev2019072401)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tf_nightly) (0.1.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tf_nightly) (41.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tf_nightly) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.16.0a0,>=1.15.0a0->tf_nightly) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.16.0a0,>=1.15.0a0->tf_nightly) (3.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SbGsznErXWt6"
      },
      "source": [
        "### 获取示例数据集\n",
        "\n",
        "我们将使用 [MNIST 数据集]((http://yann.lecun.com/exdb/mnist/) )训练模型，以演示如何保存权重。要加快演示运行速度，请仅使用前 1000 个样本："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7Nm7Tyb-gRt-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4eecaf27-743b-4330-8c14-fd2845311325"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0-dev20190724'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9rGfFwE9XVwz",
        "colab": {}
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_labels = train_labels[:1000]\n",
        "test_labels = test_labels[:1000]\n",
        "\n",
        "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
        "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "anG3iVoXyZGI"
      },
      "source": [
        "### 定义模型\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wynsOBfby0Pa"
      },
      "source": [
        "我们来构建一个简单的模型，以演示如何保存和加载权重。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0HZbJIjxyX1S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "ff4ff464-e84e-4bf3-fb40-833ab3e33e14"
      },
      "source": [
        "# Returns a short sequential model\n",
        "def create_model():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        keras.layers.Dense(512, activation=tf.keras.activations.relu, input_shape=(784,)),\n",
        "        keras.layers.Dropout(0.2),\n",
        "        keras.layers.Dense(10, activation=tf.keras.activations.softmax)\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                  loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Create a basic model instance\n",
        "model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_16 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "soDE0W_KH8rG"
      },
      "source": [
        "## 在训练期间保存检查点"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mRyd5qQQIXZm"
      },
      "source": [
        "主要用例是，在训练期间或训练结束时自动保存检查点。这样一来，您便可以使用经过训练的模型，而无需重新训练该模型，或从上次暂停的地方继续训练，以防训练过程中断。\n",
        "\n",
        "`tf.keras.callbacks.ModelCheckpoint` 是执行此任务的回调。该回调需要几个参数来配置检查点。\n",
        "\n",
        "\n",
        "\n",
        "### 检查点回调用法\n",
        "训练模型，并将 `ModelCheckpoint` 回调传递给该模型："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IFPuhwntH8VH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "7857a83f-abba-4f14-af92-ca975a760e7d"
      },
      "source": [
        "checkpoint_path = \"training_1/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create checkpoint callback\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "model.fit(train_images, train_labels,  epochs = 10,\n",
        "          validation_data = (test_images,test_labels),\n",
        "          callbacks = [cp_callback])  # pass callback to training\n",
        "\n",
        "# This may generate warnings related to saving the state of the optimizer.\n",
        "# These warnings (and similar warnings throughout this notebook)\n",
        "# are in place to discourage outdated usage, and can be ignored."
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            " 672/1000 [===================>..........] - ETA: 0s - loss: 1.4659 - acc: 0.5610\n",
            "Epoch 00001: saving model to training_1/cp.ckpt\n",
            "1000/1000 [==============================] - 1s 603us/sample - loss: 1.2143 - acc: 0.6440 - val_loss: 0.7929 - val_acc: 0.7710\n",
            "Epoch 2/10\n",
            " 704/1000 [====================>.........] - ETA: 0s - loss: 0.4703 - acc: 0.8594\n",
            "Epoch 00002: saving model to training_1/cp.ckpt\n",
            "1000/1000 [==============================] - 0s 243us/sample - loss: 0.4441 - acc: 0.8710 - val_loss: 0.5627 - val_acc: 0.8190\n",
            "Epoch 3/10\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.3137 - acc: 0.9031\n",
            "Epoch 00003: saving model to training_1/cp.ckpt\n",
            "1000/1000 [==============================] - 0s 273us/sample - loss: 0.3122 - acc: 0.9030 - val_loss: 0.4905 - val_acc: 0.8440\n",
            "Epoch 4/10\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.2156 - acc: 0.9466\n",
            "Epoch 00004: saving model to training_1/cp.ckpt\n",
            "1000/1000 [==============================] - 0s 274us/sample - loss: 0.2153 - acc: 0.9470 - val_loss: 0.4600 - val_acc: 0.8570\n",
            "Epoch 5/10\n",
            " 704/1000 [====================>.........] - ETA: 0s - loss: 0.1648 - acc: 0.9631\n",
            "Epoch 00005: saving model to training_1/cp.ckpt\n",
            "1000/1000 [==============================] - 0s 255us/sample - loss: 0.1546 - acc: 0.9670 - val_loss: 0.4535 - val_acc: 0.8630\n",
            "Epoch 6/10\n",
            " 704/1000 [====================>.........] - ETA: 0s - loss: 0.1086 - acc: 0.9815\n",
            "Epoch 00006: saving model to training_1/cp.ckpt\n",
            "1000/1000 [==============================] - 0s 249us/sample - loss: 0.1175 - acc: 0.9770 - val_loss: 0.4239 - val_acc: 0.8680\n",
            "Epoch 7/10\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9849\n",
            "Epoch 00007: saving model to training_1/cp.ckpt\n",
            "1000/1000 [==============================] - 0s 275us/sample - loss: 0.0887 - acc: 0.9850 - val_loss: 0.4292 - val_acc: 0.8640\n",
            "Epoch 8/10\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9960\n",
            "Epoch 00008: saving model to training_1/cp.ckpt\n",
            "1000/1000 [==============================] - 0s 270us/sample - loss: 0.0636 - acc: 0.9960 - val_loss: 0.4178 - val_acc: 0.8680\n",
            "Epoch 9/10\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9960\n",
            "Epoch 00009: saving model to training_1/cp.ckpt\n",
            "1000/1000 [==============================] - 0s 266us/sample - loss: 0.0521 - acc: 0.9960 - val_loss: 0.3974 - val_acc: 0.8720\n",
            "Epoch 10/10\n",
            " 704/1000 [====================>.........] - ETA: 0s - loss: 0.0390 - acc: 0.9972\n",
            "Epoch 00010: saving model to training_1/cp.ckpt\n",
            "1000/1000 [==============================] - 0s 252us/sample - loss: 0.0402 - acc: 0.9970 - val_loss: 0.4193 - val_acc: 0.8740\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3e09e71470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rlM-sgyJO084"
      },
      "source": [
        "上述代码将创建一个 TensorFlow 检查点文件集合，这些文件在每个周期结束时更新："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gXG5FVKFOVQ3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8f8ba3f6-7cde-408c-bf6b-10efe2d9d8e0"
      },
      "source": [
        "!ls {checkpoint_dir}"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t     cp.ckpt.data-00001-of-00002\n",
            "cp.ckpt.data-00000-of-00002  cp.ckpt.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wlRN_f56Pqa9"
      },
      "source": [
        "创建一个未经训练的全新模型。仅通过权重恢复模型时，您必须有一个与原始模型架构相同的模型。由于模型架构相同，因此我们可以分享权重（尽管是不同的模型实例）。\n",
        "\n",
        "现在，重新构建一个未经训练的全新模型，并用测试集对其进行评估。未训练模型的表现有很大的偶然性（准确率约为 10%）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fp5gbuiaPqCT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "e602925c-19bc-452d-8ae3-2098bbfa10b0"
      },
      "source": [
        "model = create_model()\n",
        "\n",
        "loss, acc = model.evaluate(test_images, test_labels)\n",
        "print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0725 07:33:23.666031 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "W0725 07:33:23.667701 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "W0725 07:33:23.675560 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer.decay\n",
            "W0725 07:33:23.678163 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "W0725 07:33:23.681768 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
            "W0725 07:33:23.684477 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
            "W0725 07:33:23.686849 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n",
            "W0725 07:33:23.690018 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n",
            "W0725 07:33:23.694150 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
            "W0725 07:33:23.697489 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
            "W0725 07:33:23.700890 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n",
            "W0725 07:33:23.704516 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n",
            "W0725 07:33:23.709531 139905737242496 util.py:152] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
            "W0725 07:33:23.716662 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer\n",
            "W0725 07:33:23.718000 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer.iter\n",
            "W0725 07:33:23.719709 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "W0725 07:33:23.721267 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "W0725 07:33:23.722902 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer.decay\n",
            "W0725 07:33:23.724646 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "W0725 07:33:23.726436 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
            "W0725 07:33:23.728026 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
            "W0725 07:33:23.729800 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n",
            "W0725 07:33:23.731412 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n",
            "W0725 07:33:23.733131 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
            "W0725 07:33:23.735113 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
            "W0725 07:33:23.736646 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n",
            "W0725 07:33:23.738255 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n",
            "W0725 07:33:23.739934 139905737242496 util.py:152] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 139us/sample - loss: 2.3295 - acc: 0.0710\n",
            "Untrained model, accuracy:  7.10%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1DTKpZssRSo3"
      },
      "source": [
        "然后从检查点加载权重，并重新评估："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2IZxbwiRRSD2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "aa3f1d84-631c-4122-ac9f-4a427eb907b1"
      },
      "source": [
        "model.load_weights(checkpoint_path)\n",
        "loss,acc = model.evaluate(test_images, test_labels)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 76us/sample - loss: 0.4193 - acc: 0.8740\n",
            "Restored model, accuracy: 87.40%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bpAbKkAyVPV8"
      },
      "source": [
        "### 检查点回调选项\n",
        "该回调提供了多个选项，用于为生成的检查点提供独一无二的名称，以及调整检查点创建频率。\n",
        "\n",
        "训练一个新模型，每隔 5 个周期保存一次检查点并设置唯一名称：\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mQF_dlgIVOvq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "4d367c0a-fe81-4ed5-b2b1-66f88eb5dab6"
      },
      "source": [
        "# include the epoch in the file name. (uses `str.format`)\n",
        "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    checkpoint_path, verbose=1, save_weights_only=True,\n",
        "    # Save weights, every 5-epochs.\n",
        "    period=5)\n",
        "\n",
        "model = create_model()\n",
        "model.save_weights(checkpoint_path.format(epoch=0))\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs = 50, callbacks = [cp_callback],\n",
        "          validation_data = (test_images,test_labels),\n",
        "          verbose=0)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0725 07:33:28.907587 139905737242496 callbacks.py:861] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00005: saving model to training_2/cp-0005.ckpt\n",
            "\n",
            "Epoch 00010: saving model to training_2/cp-0010.ckpt\n",
            "\n",
            "Epoch 00015: saving model to training_2/cp-0015.ckpt\n",
            "\n",
            "Epoch 00020: saving model to training_2/cp-0020.ckpt\n",
            "\n",
            "Epoch 00025: saving model to training_2/cp-0025.ckpt\n",
            "\n",
            "Epoch 00030: saving model to training_2/cp-0030.ckpt\n",
            "\n",
            "Epoch 00035: saving model to training_2/cp-0035.ckpt\n",
            "\n",
            "Epoch 00040: saving model to training_2/cp-0040.ckpt\n",
            "\n",
            "Epoch 00045: saving model to training_2/cp-0045.ckpt\n",
            "\n",
            "Epoch 00050: saving model to training_2/cp-0050.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3e0a231a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1zFrKTjjavWI"
      },
      "source": [
        "现在，看一下生成的检查点并选择最新的检查点："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p64q3-V4sXt0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "fae258fa-095b-450b-88dc-f1f81b69f02b"
      },
      "source": [
        "! ls {checkpoint_dir}"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t\t  cp-0025.ckpt.data-00001-of-00002\n",
            "cp-0000.ckpt.data-00000-of-00002  cp-0025.ckpt.index\n",
            "cp-0000.ckpt.data-00001-of-00002  cp-0030.ckpt.data-00000-of-00002\n",
            "cp-0000.ckpt.index\t\t  cp-0030.ckpt.data-00001-of-00002\n",
            "cp-0005.ckpt.data-00000-of-00002  cp-0030.ckpt.index\n",
            "cp-0005.ckpt.data-00001-of-00002  cp-0035.ckpt.data-00000-of-00002\n",
            "cp-0005.ckpt.index\t\t  cp-0035.ckpt.data-00001-of-00002\n",
            "cp-0010.ckpt.data-00000-of-00002  cp-0035.ckpt.index\n",
            "cp-0010.ckpt.data-00001-of-00002  cp-0040.ckpt.data-00000-of-00002\n",
            "cp-0010.ckpt.index\t\t  cp-0040.ckpt.data-00001-of-00002\n",
            "cp-0015.ckpt.data-00000-of-00002  cp-0040.ckpt.index\n",
            "cp-0015.ckpt.data-00001-of-00002  cp-0045.ckpt.data-00000-of-00002\n",
            "cp-0015.ckpt.index\t\t  cp-0045.ckpt.data-00001-of-00002\n",
            "cp-0020.ckpt.data-00000-of-00002  cp-0045.ckpt.index\n",
            "cp-0020.ckpt.data-00001-of-00002  cp-0050.ckpt.data-00000-of-00002\n",
            "cp-0020.ckpt.index\t\t  cp-0050.ckpt.data-00001-of-00002\n",
            "cp-0025.ckpt.data-00000-of-00002  cp-0050.ckpt.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1AN_fnuyR41H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1b5f2e0e-001e-4172-f862-0dadee496160"
      },
      "source": [
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "latest"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'training_2/cp-0050.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Zk2ciGbKg561"
      },
      "source": [
        "注意：默认的 TensorFlow 格式仅保存最近的 5 个检查点。\n",
        "\n",
        "要进行测试，请重置模型并加载最新的检查点："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3M04jyK-H3QK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "74550ec3-3b57-42d8-fec6-8162e8c8df5a"
      },
      "source": [
        "model = create_model()\n",
        "model.load_weights(latest)\n",
        "loss, acc = model.evaluate(test_images, test_labels)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 161us/sample - loss: 0.4866 - acc: 0.8770\n",
            "Restored model, accuracy: 87.70%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c2OxsJOTHxia"
      },
      "source": [
        "## 这些是什么文件？\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JtdYhvWnH2ib"
      },
      "source": [
        "上述代码将权重存储在[检查点](https://www.tensorflow.org/guide/saved_model#save_and_restore_variables)格式的文件集合中，这些文件仅包含经过训练的权重（采用二进制格式）。\n",
        "\n",
        "检查点包括：\n",
        "* 包含模型权重的一个或多个分片。 \n",
        "* 指示哪些权重存储在哪些分片中的索引文件。\n",
        "\n",
        "如果您仅在一台机器上训练模型，则您将有 1 个后缀为 .data-00000-of-00001 的分片"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S_FA-ZvxuXQV"
      },
      "source": [
        "## 手动保存权重\n",
        "在上文中，您了解了如何将权重加载到模型中。\n",
        "\n",
        "手动保存权重的方法同样也很简单，只需使用 `Model.save_weights` 方法即可。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R7W5plyZ-u9X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b9521cbf-9862-4d58-bf1e-67e25d0a3616"
      },
      "source": [
        "# Save the weights\n",
        "model.save_weights('./checkpoints/my_checkpoint')\n",
        "\n",
        "# Restore the weights\n",
        "model = create_model()\n",
        "model.load_weights('./checkpoints/my_checkpoint')\n",
        "\n",
        "loss,acc = model.evaluate(test_images, test_labels)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 159us/sample - loss: 0.4866 - acc: 0.8770\n",
            "Restored model, accuracy: 87.70%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kOGlxPRBEvV1"
      },
      "source": [
        "## 存整个模型\n",
        "整个模型可以保存到一个文件中，其中包含权重值、模型配置乃至优化器配置。这样，您就可以为模型设置检查点，并稍后从完全相同的状态继续训练，而无需访问原始代码。\n",
        "\n",
        "在 Keras 中保存完全可正常使用的模型非常有用，您可以在 TensorFlow.js 中加载它们 ，然后在网络浏览器中训练和运行它们 or convert them to run on mobile devices using TensorFlow Lite.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SkGwf-50zLNn"
      },
      "source": [
        "### 保存为 HDF5 文件\n",
        "\n",
        "Keras 使用 [HDF5](https://js.tensorflow.org/tutorials/import-keras.html) 标准提供基本的保存格式。对于我们来说，可将保存的模型视为一个二进制 blob。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m2dkmJVCGUia",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "751ad4e3-55b7-4ce1-8670-1a9b827139c4"
      },
      "source": [
        "model = create_model()\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=5)\n",
        "\n",
        "# Save entire model to a HDF5 file\n",
        "model.save('my_model.h5')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples\n",
            "Epoch 1/5\n",
            "1000/1000 [==============================] - 0s 277us/sample - loss: 1.1659 - acc: 0.6640\n",
            "Epoch 2/5\n",
            "1000/1000 [==============================] - 0s 172us/sample - loss: 0.4221 - acc: 0.8730\n",
            "Epoch 3/5\n",
            "1000/1000 [==============================] - 0s 175us/sample - loss: 0.2899 - acc: 0.9250\n",
            "Epoch 4/5\n",
            "1000/1000 [==============================] - 0s 189us/sample - loss: 0.2177 - acc: 0.9520\n",
            "Epoch 5/5\n",
            "1000/1000 [==============================] - 0s 184us/sample - loss: 0.1582 - acc: 0.9650\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GWmttMOqS68S"
      },
      "source": [
        "现在，从该文件重新创建模型："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5NDMO_7kS6Do",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "1ea4c1d6-9c1d-490b-e2be-2c297022657b"
      },
      "source": [
        "# Recreate the exact same model, including weights and optimizer.\n",
        "new_model = keras.models.load_model('my_model.h5')\n",
        "new_model.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_28 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JXQpbTicTBwt"
      },
      "source": [
        "检查其准确率："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jwEaj9DnTCVA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9dfb6993-9187-47cc-8580-025ee80df461"
      },
      "source": [
        "loss, acc = new_model.evaluate(test_images, test_labels)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 167us/sample - loss: 0.4124 - acc: 0.8700\n",
            "Restored model, accuracy: 87.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dGXqd4wWJl8O"
      },
      "source": [
        "此技巧可保存以下所有内容：\n",
        "\n",
        "* 权重值\n",
        "* 模型配置（架构）\n",
        "* 优化器配置\n",
        "\n",
        "Keras 通过检查架构来保存模型。目前，它无法保存 TensorFlow 优化器（来自 `tf.train`）。使用此类优化器时，您需要在加载模型后对其进行重新编译，使优化器的状态变松散。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kPyhgcoVzqUB"
      },
      "source": [
        "### As a `saved_model`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LtcN4VIb7JkK"
      },
      "source": [
        "Caution: This method of saving a `tf.keras` model is experimental and may change in future versions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DSWiSB0Q8c46"
      },
      "source": [
        "Build a fresh model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sI1YvCDFzpl3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "8b4c72cf-ef65-4936-d812-96f8bffa13fc"
      },
      "source": [
        "model = create_model()\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=5)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples\n",
            "Epoch 1/5\n",
            "1000/1000 [==============================] - 0s 269us/sample - loss: 1.1487 - acc: 0.6740\n",
            "Epoch 2/5\n",
            "1000/1000 [==============================] - 0s 157us/sample - loss: 0.4443 - acc: 0.8630\n",
            "Epoch 3/5\n",
            "1000/1000 [==============================] - 0s 153us/sample - loss: 0.2921 - acc: 0.9230\n",
            "Epoch 4/5\n",
            "1000/1000 [==============================] - 0s 154us/sample - loss: 0.2069 - acc: 0.9550\n",
            "Epoch 5/5\n",
            "1000/1000 [==============================] - 0s 176us/sample - loss: 0.1606 - acc: 0.9650\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3e15f54f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iUvT_3qE8hV5"
      },
      "source": [
        "Create a `saved_model`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sq8fPglI1RWA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "33b09187-41b7-49d3-847c-0f2c20e31ecd"
      },
      "source": [
        "import time\n",
        "\n",
        "saved_model_path = \"./saved_models/\"+str(int(time.time()))\n",
        "tf.contrib.saved_model.save_keras_model(model, saved_model_path)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0725 07:34:11.444093 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer.iter\n",
            "W0725 07:34:11.445657 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "W0725 07:34:11.451441 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "W0725 07:34:11.454137 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer.decay\n",
            "W0725 07:34:11.456510 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "W0725 07:34:11.458752 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
            "W0725 07:34:11.461145 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
            "W0725 07:34:11.463685 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n",
            "W0725 07:34:11.465638 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n",
            "W0725 07:34:11.468778 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
            "W0725 07:34:11.470797 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
            "W0725 07:34:11.473500 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n",
            "W0725 07:34:11.476014 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n",
            "W0725 07:34:11.478975 139905737242496 util.py:152] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
            "W0725 07:34:11.483888 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer.iter\n",
            "W0725 07:34:11.485351 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "W0725 07:34:11.487709 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "W0725 07:34:11.489487 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer.decay\n",
            "W0725 07:34:11.493132 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "W0725 07:34:11.494893 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
            "W0725 07:34:11.497046 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
            "W0725 07:34:11.499386 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n",
            "W0725 07:34:11.501509 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n",
            "W0725 07:34:11.503624 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
            "W0725 07:34:11.505389 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
            "W0725 07:34:11.507487 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n",
            "W0725 07:34:11.510146 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n",
            "W0725 07:34:11.512234 139905737242496 util.py:152] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
            "W0725 07:34:11.514656 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer.iter\n",
            "W0725 07:34:11.516498 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "W0725 07:34:11.522949 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "W0725 07:34:11.524989 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer.decay\n",
            "W0725 07:34:11.526721 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "W0725 07:34:11.528759 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
            "W0725 07:34:11.531158 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
            "W0725 07:34:11.533390 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n",
            "W0725 07:34:11.535743 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n",
            "W0725 07:34:11.537485 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
            "W0725 07:34:11.539558 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
            "W0725 07:34:11.541742 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n",
            "W0725 07:34:11.543439 139905737242496 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n",
            "W0725 07:34:11.545508 139905737242496 util.py:152] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
            "W0725 07:34:12.075832 139905737242496 export_utils.py:182] Export includes no default signature!\n",
            "W0725 07:34:12.339294 139905737242496 export_utils.py:182] Export includes no default signature!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MjpmyPfh8-1n"
      },
      "source": [
        "Have a look in the directory:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZtOvxA7V0iTv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3831505d-2fe0-425f-fae3-9f0b339dd24c"
      },
      "source": [
        "!ls {saved_model_path}"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "assets\tsaved_model.pb\tvariables\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B7qfpvpY9HCe"
      },
      "source": [
        "Reload a fresh keras model from the saved model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0YofwHdN0pxa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "d8984b86-febf-46d4-db8a-77ac6a6cb1b0"
      },
      "source": [
        "new_model = tf.contrib.saved_model.load_keras_model(saved_model_path)\n",
        "new_model.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_30 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uWwgNaz19TH2"
      },
      "source": [
        "Run the restored model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pc9e6G6w1AWG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f3802daf-bb65-4e32-8f0e-fff463ed5fcc"
      },
      "source": [
        "# The model has to be compiled before evaluating.\n",
        "# This step is not required if the saved model is only being deployed.\n",
        "\n",
        "new_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Evaluate the restored model.\n",
        "loss, acc = new_model.evaluate(test_images, test_labels)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 167us/sample - loss: 0.4368 - acc: 0.8650\n",
            "Restored model, accuracy: 86.50%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eUYTzSz5VxL2"
      },
      "source": [
        "## 后续学习计划\n",
        "这些就是使用 tf.keras 保存和加载模型的快速指南。\n",
        "\n",
        "* [tf.keras 指南](https://www.tensorflow.org/guide/keras)详细介绍了如何使用 tf.keras 保存和加载模型。\n",
        "\n",
        "* 请参阅[在 Eager 中保存](https://www.tensorflow.org/guide/eager#object_based_saving)，了解如何在 Eager Execution 期间保存模型。\n",
        "\n",
        "* [保存和恢复](https://www.tensorflow.org/guide/saved_model)指南介绍了有关 TensorFlow 保存的低阶详细信息。\n",
        "\n"
      ]
    }
  ]
}